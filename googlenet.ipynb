{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:\n",
      "b\"In file included from /tmp/try_flags_wnrjkf7v.c:3:0:\\n/usr/include/stdio.h:365:45: error: expected initializer before '__THROWNL'\\n       const char *__restrict __format, ...) __THROWNL;\\n                                             ^~~~~~~~~\\n/usr/include/stdio.h:380:26: error: expected initializer before '__THROWNL'\\n        _G_va_list __arg) __THROWNL;\\n                          ^~~~~~~~~\\n/usr/include/stdio.h:388:6: error: expected initializer before '__THROWNL'\\n      __THROWNL __attribute__ ((__format__ (__printf__, 3, 4)));\\n      ^~~~~~~~~\\n/usr/include/stdio.h:392:6: error: expected initializer before '__THROWNL'\\n      __THROWNL __attribute__ ((__format__ (__printf__, 3, 0)));\\n      ^~~~~~~~~\\n/usr/include/stdio.h:401:6: error: expected initializer before '__THROWNL'\\n      __THROWNL __attribute__ ((__format__ (__printf__, 2, 0))) __wur;\\n      ^~~~~~~~~\\n/usr/include/stdio.h:404:6: error: expected initializer before '__THROWNL'\\n      __THROWNL __attribute__ ((__format__ (__printf__, 2, 3))) __wur;\\n      ^~~~~~~~~\\n/usr/include/stdio.h:407:6: error: expected initializer before '__THROWNL'\\n      __THROWNL __attribute__ ((__format__ (__printf__, 2, 3))) __wur;\\n      ^~~~~~~~~\\nIn file included from /tmp/try_flags_wnrjkf7v.c:3:0:\\n/usr/include/stdio.h:900:6: error: expected initializer before '__THROWNL'\\n      __THROWNL __attribute__ ((__format__ (__printf__, 2, 3)));\\n      ^~~~~~~~~\\n/usr/include/stdio.h:904:6: error: expected initializer before '__THROWNL'\\n      __THROWNL __attribute__ ((__format__ (__printf__, 2, 0)));\\n      ^~~~~~~~~\\n\"\n",
      "Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:65:00.0)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os; os.environ['KERAS_BACKEND'] = 'theano'\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=cuda,floatX=float32\"\n",
    "import theano\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation, concatenate\n",
    "from keras.datasets import cifar10\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from custom_layers.googlenet_custom_layers import LRN, PoolHelper\n",
    "\n",
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from custom_layers.scale_layer import Scale\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from subprocess import check_output\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def googlenet_model(img_rows, img_cols, channel=1, num_classes=None):\n",
    "    \"\"\"\n",
    "    GoogLeNet a.k.a. Inception v1 for Keras\n",
    "    Model Schema is based on \n",
    "    https://gist.github.com/joelouismarino/a2ede9ab3928f999575423b9887abd14\n",
    "    ImageNet Pretrained Weights \n",
    "    https://drive.google.com/open?id=0B319laiAPjU3RE1maU9MMlh2dnc\n",
    "    Blog Post: \n",
    "    http://joelouismarino.github.io/blog_posts/blog_googlenet_keras.html\n",
    "    Parameters:\n",
    "      img_rows, img_cols - resolution of inputs\n",
    "      channel - 1 for grayscale, 3 for color \n",
    "      num_classes - number of class labels for our classification task\n",
    "    \"\"\"\n",
    "    \n",
    "    input = Input(shape=(channel, img_rows, img_cols))\n",
    "    conv1_7x7_s2 = Convolution2D(64,7,7,subsample=(2,2),border_mode='same',activation='relu',name='conv1/7x7_s2',W_regularizer=l2(0.0002))(input)\n",
    "    conv1_zero_pad = ZeroPadding2D(padding=(1, 1))(conv1_7x7_s2)\n",
    "    pool1_helper = PoolHelper()(conv1_zero_pad)\n",
    "    pool1_3x3_s2 = MaxPooling2D(pool_size=(3,3),strides=(2,2),border_mode='valid',name='pool1/3x3_s2')(pool1_helper)\n",
    "    pool1_norm1 = LRN(name='pool1/norm1')(pool1_3x3_s2)\n",
    "    conv2_3x3_reduce = Convolution2D(64,1,1,border_mode='same',activation='relu',name='conv2/3x3_reduce',W_regularizer=l2(0.0002))(pool1_norm1)\n",
    "    conv2_3x3 = Convolution2D(192,3,3,border_mode='same',activation='relu',name='conv2/3x3',W_regularizer=l2(0.0002))(conv2_3x3_reduce)\n",
    "    conv2_norm2 = LRN(name='conv2/norm2')(conv2_3x3)\n",
    "    conv2_zero_pad = ZeroPadding2D(padding=(1, 1))(conv2_norm2)\n",
    "    pool2_helper = PoolHelper()(conv2_zero_pad)\n",
    "    pool2_3x3_s2 = MaxPooling2D(pool_size=(3,3),strides=(2,2),border_mode='valid',name='pool2/3x3_s2')(pool2_helper)\n",
    "    \n",
    "    inception_3a_1x1 = Convolution2D(64,1,1,border_mode='same',activation='relu',name='inception_3a/1x1',W_regularizer=l2(0.0002))(pool2_3x3_s2)\n",
    "    inception_3a_3x3_reduce = Convolution2D(96,1,1,border_mode='same',activation='relu',name='inception_3a/3x3_reduce',W_regularizer=l2(0.0002))(pool2_3x3_s2)\n",
    "    inception_3a_3x3 = Convolution2D(128,3,3,border_mode='same',activation='relu',name='inception_3a/3x3',W_regularizer=l2(0.0002))(inception_3a_3x3_reduce)\n",
    "    inception_3a_5x5_reduce = Convolution2D(16,1,1,border_mode='same',activation='relu',name='inception_3a/5x5_reduce',W_regularizer=l2(0.0002))(pool2_3x3_s2)\n",
    "    inception_3a_5x5 = Convolution2D(32,5,5,border_mode='same',activation='relu',name='inception_3a/5x5',W_regularizer=l2(0.0002))(inception_3a_5x5_reduce)\n",
    "    inception_3a_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_3a/pool')(pool2_3x3_s2)\n",
    "    inception_3a_pool_proj = Convolution2D(32,1,1,border_mode='same',activation='relu',name='inception_3a/pool_proj',W_regularizer=l2(0.0002))(inception_3a_pool)\n",
    "    inception_3a_output = merge([inception_3a_1x1,inception_3a_3x3,inception_3a_5x5,inception_3a_pool_proj],mode='concat',concat_axis=1,name='inception_3a/output')\n",
    "    \n",
    "    inception_3b_1x1 = Convolution2D(128,1,1,border_mode='same',activation='relu',name='inception_3b/1x1',W_regularizer=l2(0.0002))(inception_3a_output)\n",
    "    inception_3b_3x3_reduce = Convolution2D(128,1,1,border_mode='same',activation='relu',name='inception_3b/3x3_reduce',W_regularizer=l2(0.0002))(inception_3a_output)\n",
    "    inception_3b_3x3 = Convolution2D(192,3,3,border_mode='same',activation='relu',name='inception_3b/3x3',W_regularizer=l2(0.0002))(inception_3b_3x3_reduce)\n",
    "    inception_3b_5x5_reduce = Convolution2D(32,1,1,border_mode='same',activation='relu',name='inception_3b/5x5_reduce',W_regularizer=l2(0.0002))(inception_3a_output)\n",
    "    inception_3b_5x5 = Convolution2D(96,5,5,border_mode='same',activation='relu',name='inception_3b/5x5',W_regularizer=l2(0.0002))(inception_3b_5x5_reduce)\n",
    "    inception_3b_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_3b/pool')(inception_3a_output)\n",
    "    inception_3b_pool_proj = Convolution2D(64,1,1,border_mode='same',activation='relu',name='inception_3b/pool_proj',W_regularizer=l2(0.0002))(inception_3b_pool)\n",
    "    inception_3b_output = merge([inception_3b_1x1,inception_3b_3x3,inception_3b_5x5,inception_3b_pool_proj],mode='concat',concat_axis=1,name='inception_3b/output')\n",
    "    \n",
    "    inception_3b_output_zero_pad = ZeroPadding2D(padding=(1, 1))(inception_3b_output)\n",
    "    pool3_helper = PoolHelper()(inception_3b_output_zero_pad)\n",
    "    pool3_3x3_s2 = MaxPooling2D(pool_size=(3,3),strides=(2,2),border_mode='valid',name='pool3/3x3_s2')(pool3_helper)\n",
    "    \n",
    "    inception_4a_1x1 = Convolution2D(192,1,1,border_mode='same',activation='relu',name='inception_4a/1x1',W_regularizer=l2(0.0002))(pool3_3x3_s2)\n",
    "    inception_4a_3x3_reduce = Convolution2D(96,1,1,border_mode='same',activation='relu',name='inception_4a/3x3_reduce',W_regularizer=l2(0.0002))(pool3_3x3_s2)\n",
    "    inception_4a_3x3 = Convolution2D(208,3,3,border_mode='same',activation='relu',name='inception_4a/3x3',W_regularizer=l2(0.0002))(inception_4a_3x3_reduce)\n",
    "    inception_4a_5x5_reduce = Convolution2D(16,1,1,border_mode='same',activation='relu',name='inception_4a/5x5_reduce',W_regularizer=l2(0.0002))(pool3_3x3_s2)\n",
    "    inception_4a_5x5 = Convolution2D(48,5,5,border_mode='same',activation='relu',name='inception_4a/5x5',W_regularizer=l2(0.0002))(inception_4a_5x5_reduce)\n",
    "    inception_4a_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_4a/pool')(pool3_3x3_s2)\n",
    "    inception_4a_pool_proj = Convolution2D(64,1,1,border_mode='same',activation='relu',name='inception_4a/pool_proj',W_regularizer=l2(0.0002))(inception_4a_pool)\n",
    "    inception_4a_output = merge([inception_4a_1x1,inception_4a_3x3,inception_4a_5x5,inception_4a_pool_proj],mode='concat',concat_axis=1,name='inception_4a/output')\n",
    "    \n",
    "    loss1_ave_pool = AveragePooling2D(pool_size=(5,5),strides=(3,3),name='loss1/ave_pool')(inception_4a_output)\n",
    "    loss1_conv = Convolution2D(128,1,1,border_mode='same',activation='relu',name='loss1/conv',W_regularizer=l2(0.0002))(loss1_ave_pool)\n",
    "    loss1_flat = Flatten()(loss1_conv)\n",
    "    loss1_fc = Dense(1024,activation='relu',name='loss1/fc',W_regularizer=l2(0.0002))(loss1_flat)\n",
    "    loss1_drop_fc = Dropout(0.7)(loss1_fc)\n",
    "    loss1_classifier = Dense(1000,name='loss1/classifier',W_regularizer=l2(0.0002))(loss1_drop_fc)\n",
    "    loss1_classifier_act = Activation('softmax')(loss1_classifier)\n",
    "    \n",
    "    inception_4b_1x1 = Convolution2D(160,1,1,border_mode='same',activation='relu',name='inception_4b/1x1',W_regularizer=l2(0.0002))(inception_4a_output)\n",
    "    inception_4b_3x3_reduce = Convolution2D(112,1,1,border_mode='same',activation='relu',name='inception_4b/3x3_reduce',W_regularizer=l2(0.0002))(inception_4a_output)\n",
    "    inception_4b_3x3 = Convolution2D(224,3,3,border_mode='same',activation='relu',name='inception_4b/3x3',W_regularizer=l2(0.0002))(inception_4b_3x3_reduce)\n",
    "    inception_4b_5x5_reduce = Convolution2D(24,1,1,border_mode='same',activation='relu',name='inception_4b/5x5_reduce',W_regularizer=l2(0.0002))(inception_4a_output)\n",
    "    inception_4b_5x5 = Convolution2D(64,5,5,border_mode='same',activation='relu',name='inception_4b/5x5',W_regularizer=l2(0.0002))(inception_4b_5x5_reduce)\n",
    "    inception_4b_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_4b/pool')(inception_4a_output)\n",
    "    inception_4b_pool_proj = Convolution2D(64,1,1,border_mode='same',activation='relu',name='inception_4b/pool_proj',W_regularizer=l2(0.0002))(inception_4b_pool)\n",
    "    inception_4b_output = merge([inception_4b_1x1,inception_4b_3x3,inception_4b_5x5,inception_4b_pool_proj],mode='concat',concat_axis=1,name='inception_4b_output')\n",
    "    \n",
    "    inception_4c_1x1 = Convolution2D(128,1,1,border_mode='same',activation='relu',name='inception_4c/1x1',W_regularizer=l2(0.0002))(inception_4b_output)\n",
    "    inception_4c_3x3_reduce = Convolution2D(128,1,1,border_mode='same',activation='relu',name='inception_4c/3x3_reduce',W_regularizer=l2(0.0002))(inception_4b_output)\n",
    "    inception_4c_3x3 = Convolution2D(256,3,3,border_mode='same',activation='relu',name='inception_4c/3x3',W_regularizer=l2(0.0002))(inception_4c_3x3_reduce)\n",
    "    inception_4c_5x5_reduce = Convolution2D(24,1,1,border_mode='same',activation='relu',name='inception_4c/5x5_reduce',W_regularizer=l2(0.0002))(inception_4b_output)\n",
    "    inception_4c_5x5 = Convolution2D(64,5,5,border_mode='same',activation='relu',name='inception_4c/5x5',W_regularizer=l2(0.0002))(inception_4c_5x5_reduce)\n",
    "    inception_4c_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_4c/pool')(inception_4b_output)\n",
    "    inception_4c_pool_proj = Convolution2D(64,1,1,border_mode='same',activation='relu',name='inception_4c/pool_proj',W_regularizer=l2(0.0002))(inception_4c_pool)\n",
    "    inception_4c_output = merge([inception_4c_1x1,inception_4c_3x3,inception_4c_5x5,inception_4c_pool_proj],mode='concat',concat_axis=1,name='inception_4c/output')\n",
    "    \n",
    "    inception_4d_1x1 = Convolution2D(112,1,1,border_mode='same',activation='relu',name='inception_4d/1x1',W_regularizer=l2(0.0002))(inception_4c_output)\n",
    "    inception_4d_3x3_reduce = Convolution2D(144,1,1,border_mode='same',activation='relu',name='inception_4d/3x3_reduce',W_regularizer=l2(0.0002))(inception_4c_output)\n",
    "    inception_4d_3x3 = Convolution2D(288,3,3,border_mode='same',activation='relu',name='inception_4d/3x3',W_regularizer=l2(0.0002))(inception_4d_3x3_reduce)\n",
    "    inception_4d_5x5_reduce = Convolution2D(32,1,1,border_mode='same',activation='relu',name='inception_4d/5x5_reduce',W_regularizer=l2(0.0002))(inception_4c_output)\n",
    "    inception_4d_5x5 = Convolution2D(64,5,5,border_mode='same',activation='relu',name='inception_4d/5x5',W_regularizer=l2(0.0002))(inception_4d_5x5_reduce)\n",
    "    inception_4d_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_4d/pool')(inception_4c_output)\n",
    "    inception_4d_pool_proj = Convolution2D(64,1,1,border_mode='same',activation='relu',name='inception_4d/pool_proj',W_regularizer=l2(0.0002))(inception_4d_pool)\n",
    "    inception_4d_output = merge([inception_4d_1x1,inception_4d_3x3,inception_4d_5x5,inception_4d_pool_proj],mode='concat',concat_axis=1,name='inception_4d/output')\n",
    "    \n",
    "    loss2_ave_pool = AveragePooling2D(pool_size=(5,5),strides=(3,3),name='loss2/ave_pool')(inception_4d_output)\n",
    "    loss2_conv = Convolution2D(128,1,1,border_mode='same',activation='relu',name='loss2/conv',W_regularizer=l2(0.0002))(loss2_ave_pool)\n",
    "    loss2_flat = Flatten()(loss2_conv)\n",
    "    loss2_fc = Dense(1024,activation='relu',name='loss2/fc',W_regularizer=l2(0.0002))(loss2_flat)\n",
    "    loss2_drop_fc = Dropout(0.7)(loss2_fc)\n",
    "    loss2_classifier = Dense(1000,name='loss2/classifier',W_regularizer=l2(0.0002))(loss2_drop_fc)\n",
    "    loss2_classifier_act = Activation('softmax')(loss2_classifier)\n",
    "    \n",
    "    inception_4e_1x1 = Convolution2D(256,1,1,border_mode='same',activation='relu',name='inception_4e/1x1',W_regularizer=l2(0.0002))(inception_4d_output)\n",
    "    inception_4e_3x3_reduce = Convolution2D(160,1,1,border_mode='same',activation='relu',name='inception_4e/3x3_reduce',W_regularizer=l2(0.0002))(inception_4d_output)\n",
    "    inception_4e_3x3 = Convolution2D(320,3,3,border_mode='same',activation='relu',name='inception_4e/3x3',W_regularizer=l2(0.0002))(inception_4e_3x3_reduce)\n",
    "    inception_4e_5x5_reduce = Convolution2D(32,1,1,border_mode='same',activation='relu',name='inception_4e/5x5_reduce',W_regularizer=l2(0.0002))(inception_4d_output)\n",
    "    inception_4e_5x5 = Convolution2D(128,5,5,border_mode='same',activation='relu',name='inception_4e/5x5',W_regularizer=l2(0.0002))(inception_4e_5x5_reduce)\n",
    "    inception_4e_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_4e/pool')(inception_4d_output)\n",
    "    inception_4e_pool_proj = Convolution2D(128,1,1,border_mode='same',activation='relu',name='inception_4e/pool_proj',W_regularizer=l2(0.0002))(inception_4e_pool)\n",
    "    inception_4e_output = merge([inception_4e_1x1,inception_4e_3x3,inception_4e_5x5,inception_4e_pool_proj],mode='concat',concat_axis=1,name='inception_4e/output')\n",
    "    \n",
    "    inception_4e_output_zero_pad = ZeroPadding2D(padding=(1, 1))(inception_4e_output)\n",
    "    pool4_helper = PoolHelper()(inception_4e_output_zero_pad)\n",
    "    pool4_3x3_s2 = MaxPooling2D(pool_size=(3,3),strides=(2,2),border_mode='valid',name='pool4/3x3_s2')(pool4_helper)\n",
    "    \n",
    "    inception_5a_1x1 = Convolution2D(256,1,1,border_mode='same',activation='relu',name='inception_5a/1x1',W_regularizer=l2(0.0002))(pool4_3x3_s2)\n",
    "    inception_5a_3x3_reduce = Convolution2D(160,1,1,border_mode='same',activation='relu',name='inception_5a/3x3_reduce',W_regularizer=l2(0.0002))(pool4_3x3_s2)\n",
    "    inception_5a_3x3 = Convolution2D(320,3,3,border_mode='same',activation='relu',name='inception_5a/3x3',W_regularizer=l2(0.0002))(inception_5a_3x3_reduce)\n",
    "    inception_5a_5x5_reduce = Convolution2D(32,1,1,border_mode='same',activation='relu',name='inception_5a/5x5_reduce',W_regularizer=l2(0.0002))(pool4_3x3_s2)\n",
    "    inception_5a_5x5 = Convolution2D(128,5,5,border_mode='same',activation='relu',name='inception_5a/5x5',W_regularizer=l2(0.0002))(inception_5a_5x5_reduce)\n",
    "    inception_5a_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_5a/pool')(pool4_3x3_s2)\n",
    "    inception_5a_pool_proj = Convolution2D(128,1,1,border_mode='same',activation='relu',name='inception_5a/pool_proj',W_regularizer=l2(0.0002))(inception_5a_pool)\n",
    "    inception_5a_output = merge([inception_5a_1x1,inception_5a_3x3,inception_5a_5x5,inception_5a_pool_proj],mode='concat',concat_axis=1,name='inception_5a/output')\n",
    "    \n",
    "    inception_5b_1x1 = Convolution2D(384,1,1,border_mode='same',activation='relu',name='inception_5b/1x1',W_regularizer=l2(0.0002))(inception_5a_output)\n",
    "    inception_5b_3x3_reduce = Convolution2D(192,1,1,border_mode='same',activation='relu',name='inception_5b/3x3_reduce',W_regularizer=l2(0.0002))(inception_5a_output)\n",
    "    inception_5b_3x3 = Convolution2D(384,3,3,border_mode='same',activation='relu',name='inception_5b/3x3',W_regularizer=l2(0.0002))(inception_5b_3x3_reduce)\n",
    "    inception_5b_5x5_reduce = Convolution2D(48,1,1,border_mode='same',activation='relu',name='inception_5b/5x5_reduce',W_regularizer=l2(0.0002))(inception_5a_output)\n",
    "    inception_5b_5x5 = Convolution2D(128,5,5,border_mode='same',activation='relu',name='inception_5b/5x5',W_regularizer=l2(0.0002))(inception_5b_5x5_reduce)\n",
    "    inception_5b_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_5b/pool')(inception_5a_output)\n",
    "    inception_5b_pool_proj = Convolution2D(128,1,1,border_mode='same',activation='relu',name='inception_5b/pool_proj',W_regularizer=l2(0.0002))(inception_5b_pool)\n",
    "    inception_5b_output = merge([inception_5b_1x1,inception_5b_3x3,inception_5b_5x5,inception_5b_pool_proj],mode='concat',concat_axis=1,name='inception_5b/output')\n",
    "    \n",
    "    pool5_7x7_s1 = AveragePooling2D(pool_size=(7,7),strides=(1,1),name='pool5/7x7_s2')(inception_5b_output)\n",
    "    loss3_flat = Flatten()(pool5_7x7_s1)\n",
    "    pool5_drop_7x7_s1 = Dropout(0.4)(loss3_flat)\n",
    "    loss3_classifier = Dense(1000,name='loss3/classifier',W_regularizer=l2(0.0002))(pool5_drop_7x7_s1)\n",
    "    loss3_classifier_act = Activation('softmax',name='prob')(loss3_classifier)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(input=input, output=[loss1_classifier_act,loss2_classifier_act,loss3_classifier_act])\n",
    "    \n",
    "    # Load ImageNet pre-trained data \n",
    "    model.load_weights('/home/sahand/Projects/Kaggle-dog-breeds-identification/imagenet_models/googlenet_weights.h5')\n",
    "    \n",
    "    # Truncate and replace softmax layer for transfer learning\n",
    "    # Cannot use model.layers.pop() since model is not of Sequential() type\n",
    "    # The method below works since pre-trained weights are stored in layers but not in the model\n",
    "    loss3_classifier_statefarm = Dense(num_classes,name='loss3/classifier',W_regularizer=l2(0.0002))(pool5_drop_7x7_s1)\n",
    "    loss3_classifier_act_statefarm = Activation('softmax',name='prob')(loss3_classifier_statefarm)\n",
    "    loss2_classifier_statefarm = Dense(num_classes,name='loss2/classifier',W_regularizer=l2(0.0002))(loss2_drop_fc)\n",
    "    loss2_classifier_act_statefarm = Activation('softmax')(loss2_classifier_statefarm)\n",
    "    loss1_classifier_statefarm = Dense(num_classes,name='loss1/classifier',W_regularizer=l2(0.0002))(loss1_drop_fc)\n",
    "    loss1_classifier_act_statefarm = Activation('softmax')(loss1_classifier_statefarm)\n",
    "\n",
    "    # Create another model with our customized softmax\n",
    "    model = Model(input=input, output=[loss1_classifier_act_statefarm,loss2_classifier_act_statefarm,loss3_classifier_act_statefarm])\n",
    "\n",
    "    # Learning rate is changed to 0.001\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snd_data_split_3(X,Y,train_proportion,test_proportion,validation_proportion):\n",
    "    size_1 = 1 - train_proportion\n",
    "    size_2 = validation_proportion/(test_proportion+validation_proportion)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=size_1)\n",
    "    x_test, x_valid, y_test, y_valid = train_test_split(x_test, y_test, test_size=size_2)\n",
    "    return x_train,x_test,x_valid,y_train,y_test,y_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 344/15702 [00:00<00:04, 3425.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate a tensor of images for train/test/validation sets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15702/15702 [00:04<00:00, 3448.15it/s]\n",
      "100%|██████████| 2243/2243 [00:00<00:00, 3355.51it/s]\n",
      "100%|██████████| 4487/4487 [00:01<00:00, 3622.68it/s]\n"
     ]
    }
   ],
   "source": [
    "    img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "    channel = 3\n",
    "    num_classes = 2 \n",
    "    batch_size = 64 \n",
    "    nb_epoch = 10\n",
    "    \n",
    "    TrainDataRaw = pd.read_csv('/home/sahand/Desktop/output/log.csv',sep=',',header=None)\n",
    "    labeled_image_list = TrainDataRaw[0].unique()\n",
    "    np.random.seed(10)\n",
    "    \n",
    "    remove_all = 205000 # Number of data points for dropping\n",
    "    drop_indices = np.random.choice(TrainDataRaw.index, remove_all, replace=False)\n",
    "    TrainDataRaw = TrainDataRaw.drop(drop_indices)\n",
    "    \n",
    "    TrainDataRaw_0 = TrainDataRaw.loc[TrainDataRaw[4]==0]\n",
    "    TrainDataRaw_1 = TrainDataRaw.loc[TrainDataRaw[4]==1]\n",
    "    TrainDataRaw_2 = TrainDataRaw.loc[TrainDataRaw[4]==2]\n",
    "    \n",
    "    TrainDataRaw_0 = TrainDataRaw_0.reset_index()\n",
    "    TrainDataRaw_0 = TrainDataRaw_0.drop(\"index\",axis=1)\n",
    "    TrainDataRaw_1 = TrainDataRaw_1.reset_index()\n",
    "    TrainDataRaw_1 = TrainDataRaw_1.drop(\"index\",axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    remove_n = 25000 # Number of non-cracks for dropping\n",
    "    drop_indices = np.random.choice(TrainDataRaw_0.index, remove_n, replace=False)\n",
    "    TrainDataRaw_0 = TrainDataRaw_0.drop(drop_indices)\n",
    "    \n",
    "    TrainDataRaw_Full = TrainDataRaw_0.append(TrainDataRaw_1)\n",
    "    TrainDataRaw_Full = TrainDataRaw_Full.append(TrainDataRaw_2)\n",
    "    TrainDataRaw_Full = TrainDataRaw_Full.reset_index()\n",
    "    TrainDataRaw_Full = TrainDataRaw_Full.drop(\"index\",axis=1)\n",
    "    \n",
    "    # SHUFFLE DATA\n",
    "    TrainDataRaw_Full = TrainDataRaw_Full.sample(frac=1).reset_index(drop=True)\n",
    "    TrainDataRaw_Full = TrainDataRaw_Full.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    Y_raw = TrainDataRaw_Full[4] #(5th column= cat)\n",
    "    X_files = TrainDataRaw_Full[2] #(3th column=directories)\n",
    "    x_train_raw,x_test_raw,x_valid_raw,y_train,y_test,y_valid = snd_data_split_3(X_files,Y_raw,train_proportion=0.7,test_proportion=0.1,validation_proportion=0.2)\n",
    "\n",
    "        \n",
    "    im_size = 224\n",
    "    x_train = []\n",
    "    x_valid = []\n",
    "    x_test = []\n",
    "  \n",
    "    print(\"generate a tensor of images for train/test/validation sets\")\n",
    "    \n",
    "    \n",
    "\n",
    "    for f in tqdm(x_train_raw):\n",
    "        img = cv2.imread(f)\n",
    "        x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "        \n",
    "    \n",
    "    for f in tqdm(x_test_raw):\n",
    "        img = cv2.imread(f)\n",
    "        x_test.append(cv2.resize(img, (im_size, im_size)))\n",
    "        \n",
    "    \n",
    "    for f in tqdm(x_valid_raw):\n",
    "        img = cv2.imread(f)\n",
    "        x_valid.append(cv2.resize(img, (im_size, im_size)))\n",
    "        \n",
    "    dummies_created = False\n",
    "    data_reshaped = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy labels are created\n"
     ]
    }
   ],
   "source": [
    "if dummies_created==False:\n",
    "    y_train = pd.get_dummies(y_train)\n",
    "    y_test = pd.get_dummies(y_test)\n",
    "    y_valid = pd.get_dummies(y_valid)\n",
    "    dummies_created = True\n",
    "    print('dummy labels are created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape\n",
      "(15702, 3, 224, 224)\n",
      "(15702, 2)\n",
      "test data shape\n",
      "(2243, 3, 224, 224)\n",
      "(2243, 2)\n",
      "valid data shape\n",
      "(4487, 3, 224, 224)\n",
      "(4487, 2)\n",
      "data reshaped and normalized\n"
     ]
    }
   ],
   "source": [
    "if data_reshaped==False:\n",
    "    y_train = np.array(y_train, np.uint8)\n",
    "    x_train = np.array(x_train, np.float32) / 255.\n",
    "    x_train = x_train.reshape(x_train.shape[0],x_train.shape[3],x_train.shape[1],x_train.shape[2])\n",
    "    print(\"train data shape\")\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    x_test  = np.array(x_test, np.float32) / 255.\n",
    "    x_test = x_test.reshape(x_test.shape[0],x_test.shape[3],x_test.shape[1],x_test.shape[2])\n",
    "    print(\"test data shape\")\n",
    "    print(x_test.shape)\n",
    "    print(y_test.shape)\n",
    "    x_valid  = np.array(x_valid, np.float32) / 255.\n",
    "    x_valid = x_valid.reshape(x_valid.shape[0],x_valid.shape[3],x_valid.shape[1],x_valid.shape[2])\n",
    "    print(\"valid data shape\")\n",
    "    print(x_valid.shape)\n",
    "    print(y_valid.shape) \n",
    "    data_reshaped = True\n",
    "    print('data reshaped and normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (7, 7), activation=\"relu\", name=\"conv1/7x7_s2\", strides=(2, 2), padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name=\"pool1/3x3_s2\", padding=\"valid\")`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", name=\"conv2/3x3_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), activation=\"relu\", name=\"conv2/3x3\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name=\"pool2/3x3_s2\", padding=\"valid\")`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", name=\"inception_3a/1x1\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (1, 1), activation=\"relu\", name=\"inception_3a/3x3_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"inception_3a/3x3\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\", name=\"inception_3a/5x5_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), activation=\"relu\", name=\"inception_3a/5x5\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(1, 1), name=\"inception_3a/pool\", padding=\"same\")`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\", name=\"inception_3a/pool_proj\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/keras/legacy/layers.py:460: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"inception_3b/1x1\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"inception_3b/3x3_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), activation=\"relu\", name=\"inception_3b/3x3\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\", name=\"inception_3b/5x5_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (5, 5), activation=\"relu\", name=\"inception_3b/5x5\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:43: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(1, 1), name=\"inception_3b/pool\", padding=\"same\")`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", name=\"inception_3b/pool_proj\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:45: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name=\"pool3/3x3_s2\", padding=\"valid\")`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (1, 1), activation=\"relu\", name=\"inception_4a/1x1\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (1, 1), activation=\"relu\", name=\"inception_4a/3x3_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(208, (3, 3), activation=\"relu\", name=\"inception_4a/3x3\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:54: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\", name=\"inception_4a/5x5_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), activation=\"relu\", name=\"inception_4a/5x5\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(1, 1), name=\"inception_4a/pool\", padding=\"same\")`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:57: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", name=\"inception_4a/pool_proj\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:58: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"loss1/conv\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:63: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, activation=\"relu\", name=\"loss1/fc\", kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:65: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, name=\"loss1/classifier\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:68: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(160, (1, 1), activation=\"relu\", name=\"inception_4b/1x1\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:69: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(112, (1, 1), activation=\"relu\", name=\"inception_4b/3x3_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:70: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(224, (3, 3), activation=\"relu\", name=\"inception_4b/3x3\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:71: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (1, 1), activation=\"relu\", name=\"inception_4b/5x5_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:72: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), activation=\"relu\", name=\"inception_4b/5x5\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:73: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(1, 1), name=\"inception_4b/pool\", padding=\"same\")`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:74: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", name=\"inception_4b/pool_proj\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:75: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/keras/legacy/layers.py:460: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"inception_4c/1x1\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:78: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"inception_4c/3x3_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:79: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"inception_4c/3x3\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:80: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (1, 1), activation=\"relu\", name=\"inception_4c/5x5_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:81: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), activation=\"relu\", name=\"inception_4c/5x5\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:82: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(1, 1), name=\"inception_4c/pool\", padding=\"same\")`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:83: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", name=\"inception_4c/pool_proj\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:84: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(112, (1, 1), activation=\"relu\", name=\"inception_4d/1x1\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(144, (1, 1), activation=\"relu\", name=\"inception_4d/3x3_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:88: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(288, (3, 3), activation=\"relu\", name=\"inception_4d/3x3\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\", name=\"inception_4d/5x5_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:90: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), activation=\"relu\", name=\"inception_4d/5x5\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:91: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(1, 1), name=\"inception_4d/pool\", padding=\"same\")`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:92: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", name=\"inception_4d/pool_proj\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:93: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:96: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"loss2/conv\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:98: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, activation=\"relu\", name=\"loss2/fc\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:100: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, name=\"loss2/classifier\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:103: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), activation=\"relu\", name=\"inception_4e/1x1\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:104: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(160, (1, 1), activation=\"relu\", name=\"inception_4e/3x3_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:105: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(320, (3, 3), activation=\"relu\", name=\"inception_4e/3x3\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:106: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\", name=\"inception_4e/5x5_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:107: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5), activation=\"relu\", name=\"inception_4e/5x5\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(1, 1), name=\"inception_4e/pool\", padding=\"same\")`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:109: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"inception_4e/pool_proj\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:110: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:114: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name=\"pool4/3x3_s2\", padding=\"valid\")`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:116: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), activation=\"relu\", name=\"inception_5a/1x1\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:117: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(160, (1, 1), activation=\"relu\", name=\"inception_5a/3x3_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:118: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(320, (3, 3), activation=\"relu\", name=\"inception_5a/3x3\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:119: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\", name=\"inception_5a/5x5_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:120: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5), activation=\"relu\", name=\"inception_5a/5x5\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:121: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(1, 1), name=\"inception_5a/pool\", padding=\"same\")`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:122: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"inception_5a/pool_proj\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:123: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:125: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(384, (1, 1), activation=\"relu\", name=\"inception_5b/1x1\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:126: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (1, 1), activation=\"relu\", name=\"inception_5b/3x3_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:127: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(384, (3, 3), activation=\"relu\", name=\"inception_5b/3x3\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:128: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (1, 1), activation=\"relu\", name=\"inception_5b/5x5_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:129: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5), activation=\"relu\", name=\"inception_5b/5x5\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:130: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(1, 1), name=\"inception_5b/pool\", padding=\"same\")`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:131: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"inception_5b/pool_proj\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:132: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:137: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, name=\"loss3/classifier\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:141: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=/input_1, outputs=[Softmax.0...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:149: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2, name=\"loss3/classifier\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:151: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2, name=\"loss2/classifier\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:153: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2, name=\"loss1/classifier\", kernel_regularizer=<keras.reg...)`\n",
      "/home/sahand/anaconda3/envs/py3-theano/lib/python3.6/site-packages/ipykernel_launcher.py:157: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=/input_1, outputs=[Softmax.0...)`\n"
     ]
    }
   ],
   "source": [
    "    # Load our model\n",
    "    model = googlenet_model(img_rows, img_cols, channel, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15702 samples, validate on 4487 samples\n",
      "Epoch 1/10\n",
      "15696/15702 [============================>.] - ETA: 0s - loss: 3.7338 - activation_4_loss: 0.7172 - activation_3_loss: 0.8106 - prob_loss: 0.6784 - activation_4_acc: 0.5791 - activation_3_acc: 0.5571 - prob_acc: 0.6004"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[ 2  3  4  5  6  7  8  9 10 11 12 13 14 15] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f28a8313e7a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m           )\n",
      "\u001b[0;32m~/anaconda3/envs/py3-theano/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-theano/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1168\u001b[0m                         val_outs = self._test_loop(val_f, val_ins,\n\u001b[1;32m   1169\u001b[0m                                                    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m                                                    verbose=0)\n\u001b[0m\u001b[1;32m   1171\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m                             \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-theano/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-theano/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-theano/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-theano/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-theano/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-theano/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1327\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[ 2  3  4  5  6  7  8  9 10 11 12 13 14 15] not in index'"
     ]
    }
   ],
   "source": [
    "    # Start Fine-tuning. \n",
    "    # Notice that googlenet takes 3 sets of labels for outputs, one for each auxillary classifier\n",
    "    model.fit(x_train, [y_train, y_train, y_train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              shuffle=True,\n",
    "              verbose=1,\n",
    "              validation_data=(x_valid, [y_valid, y_valid, y_valid])\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Make predictions\n",
    "    predictions_test = model.predict(x_test, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    # Combine 3 set of outputs using averaging\n",
    "    predictions_test = sum(predictions_test)/len(predictions_test)\n",
    "\n",
    "    # Cross-entropy loss score\n",
    "    score = log_loss(y_test, predictions_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df_confusion = pd.crosstab(y_test, predictions_test, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "    print(df_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Example to fine-tune on 3000 samples from Cifar10\n",
    "\n",
    "    img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "    channel = 3\n",
    "    num_classes = 2 \n",
    "    batch_size = 16 \n",
    "    nb_epoch = 10\n",
    "    \n",
    "    TrainDataRaw = pd.read_csv('/home/sahand/Desktop/output/log.cvs',sep=',',header=None)\n",
    "    labeled_image_list = TrainDataRaw[0].unique()\n",
    "    np.random.seed(10)\n",
    "    \n",
    "    remove_all = 0 # Number of non-cracks for dropping\n",
    "    drop_indices = np.random.choice(TrainDataRaw.index, remove_all, replace=False)\n",
    "    TrainDataRaw = TrainDataRaw.drop(drop_indices)\n",
    "    \n",
    "    TrainDataRaw_0 = TrainDataRaw.loc[TrainDataRaw[4]==0]\n",
    "    TrainDataRaw_1 = TrainDataRaw.loc[TrainDataRaw[4]==1]\n",
    "    TrainDataRaw_2 = TrainDataRaw.loc[TrainDataRaw[4]==2]\n",
    "    \n",
    "    TrainDataRaw_0 = TrainDataRaw_0.reset_index()\n",
    "    TrainDataRaw_0 = TrainDataRaw_0.drop(\"index\",axis=1)\n",
    "    TrainDataRaw_1 = TrainDataRaw_1.reset_index()\n",
    "    TrainDataRaw_1 = TrainDataRaw_1.drop(\"index\",axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    remove_n = 1 # Number of non-cracks for dropping\n",
    "    drop_indices = np.random.choice(TrainDataRaw_0.index, remove_n, replace=False)\n",
    "    TrainDataRaw_0 = TrainDataRaw_0.drop(drop_indices)\n",
    "    \n",
    "    TrainDataRaw_Full = TrainDataRaw_0.append(TrainDataRaw_1)\n",
    "    TrainDataRaw_Full = TrainDataRaw_Full.append(TrainDataRaw_2)\n",
    "    TrainDataRaw_Full = TrainDataRaw_Full.reset_index()\n",
    "    TrainDataRaw_Full = TrainDataRaw_Full.drop(\"index\",axis=1)\n",
    "    \n",
    "    # SHUFFLE DATA\n",
    "    TrainDataRaw_Full = TrainDataRaw_Full.sample(frac=1).reset_index(drop=True)\n",
    "    TrainDataRaw_Full = TrainDataRaw_Full.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    Y_raw = TrainDataRaw_Full[4] #(5th column= cat)\n",
    "    X_files = TrainDataRaw_Full[2] #(3th column=directories)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=size_1)\n",
    "    \n",
    "    im_size = 224\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "  \n",
    "    #generate a tensor of images\n",
    "    \n",
    "    i = 0\n",
    "    for f, breed in tqdm(df_train.values):\n",
    "        img = cv2.imread(f)\n",
    "        label = one_hot_labels[i]\n",
    "        x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "        y_train.append(label)\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    for f in tqdm(df_test['id'].values):\n",
    "        img = cv2.imread(directory_path+'test/{}.jpg'.format(f))\n",
    "        x_test.append(cv2.resize(img, (im_size, im_size)))\n",
    "\n",
    "    y_train_raw = np.array(y_train, np.uint8)\n",
    "    x_train_raw = np.array(x_train, np.float32) / 255.\n",
    "    x_test  = np.array(x_test, np.float32) / 255.\n",
    "\n",
    "    print(x_train_raw.shape)\n",
    "    print(y_train_raw.shape)\n",
    "    print(x_test.shape)\n",
    "\n",
    "    num_class = y_train_raw.shape[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Load Cifar10 data. Please implement your own load_data() module for your own dataset\n",
    "    X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=0.1, random_state=1)\n",
    "\n",
    "    # Load our model\n",
    "    model = googlenet_model(img_rows, img_cols, channel, num_classes)\n",
    "\n",
    "    # Start Fine-tuning. \n",
    "    # Notice that googlenet takes 3 sets of labels for outputs, one for each auxillary classifier\n",
    "    model.fit(X_train, [Y_train, Y_train, Y_train],\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              shuffle=True,\n",
    "              verbose=1,\n",
    "              validation_data=(X_valid, [Y_valid, Y_valid, Y_valid]),\n",
    "              )\n",
    "\n",
    "    # Make predictions\n",
    "    predictions_valid = model.predict(X_valid, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    # Combine 3 set of outputs using averaging\n",
    "    predictions_valid = sum(predictions_valid)/len(predictions_valid)\n",
    "\n",
    "    # Cross-entropy loss score\n",
    "    score = log_loss(Y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
